{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ› ï¸ Day 2: The Mechanics of Agentic AI\n",
    "**Focus:** Tools, Binding, and the Manual Execution Loop.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Agenda\n",
    "1. **Built-in Tools:** Leveraging the community ecosystem.\n",
    "2. **Custom Tools & Pydantic:** Creating robust, type-safe tools.\n",
    "3. **Binding:** How the LLM \"sees\" functions.\n",
    "4. **The Message Stack:** Understanding `HumanMessage`, `AIMessage`, and `ToolMessage`.\n",
    "5. **Manual Execution:** Building a ReAct loop from scratch (No `AgentExecutor`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a896d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. SETUP\n",
    "# 1. Setup Environment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install pip-system-certs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46120fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the \"Brain\" (LLM)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7769a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ddgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f91399",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pip-system-certs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da303b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "DDGSException",
     "evalue": "RuntimeError: RuntimeError('error sending request for url (https://www.bing.com/search?q=When+google+antigravity+launched%3F&pq=When+google+antigravity+launched%3F&cc=wt&filters=ex1%3A%22ez5_20055_20420%22): client error (Connect)\\n\\nCaused by:\\n    0: client error (Connect)\\n    1: TLS handshake failed: cert verification failed - unable to get local issuer certificate [CERTIFICATE_VERIFY_FAILED]\\n    2: [CERTIFICATE_VERIFY_FAILED]\\n    3: [CERTIFICATE_VERIFY_FAILED]')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDDGSException\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m search_tool = DuckDuckGoSearchRun()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Test it directly (No LLM involved yet)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m result = \u001b[43msearch_tool\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhen google antigravity launched?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Internet Search SUCCESS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:605\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    597\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    599\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    602\u001b[39m     **kwargs: Any,\n\u001b[32m    603\u001b[39m ) -> Any:\n\u001b[32m    604\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:932\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    931\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m932\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    933\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    934\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:898\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m._run):\n\u001b[32m    897\u001b[39m         tool_kwargs |= {config_param: config}\n\u001b[32m--> \u001b[39m\u001b[32m898\u001b[39m     response = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    900\u001b[39m     msg = (\n\u001b[32m    901\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSince response_format=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    902\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33ma two-tuple of the message content and raw tool output is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    903\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected. Instead, generated response is of type: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_community\\tools\\ddg_search\\tool.py:74\u001b[39m, in \u001b[36mDuckDuckGoSearchRun._run\u001b[39m\u001b[34m(self, query, run_manager)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run\u001b[39m(\n\u001b[32m     69\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     70\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m     71\u001b[39m     run_manager: Optional[CallbackManagerForToolRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     72\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     73\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_wrapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:114\u001b[39m, in \u001b[36mDuckDuckGoSearchAPIWrapper.run\u001b[39m\u001b[34m(self, query)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run query through DuckDuckGo and return concatenated results.\"\"\"\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source == \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ddgs_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source == \u001b[33m\"\u001b[39m\u001b[33mnews\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    116\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._ddgs_news(query)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:64\u001b[39m, in \u001b[36mDuckDuckGoSearchAPIWrapper._ddgs_text\u001b[39m\u001b[34m(self, query, max_results)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mddgs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DDGS\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m DDGS() \u001b[38;5;28;01mas\u001b[39;00m ddgs:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     ddgs_gen = \u001b[43mddgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafesearch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msafesearch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimelimit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ddgs_gen:\n\u001b[32m     73\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m ddgs_gen]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AgenticAI\\venv\\Lib\\site-packages\\ddgs\\ddgs.py:219\u001b[39m, in \u001b[36mDDGS.text\u001b[39m\u001b[34m(self, query, **kwargs)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:  \u001b[38;5;66;03m# noqa: ANN401\u001b[39;00m\n\u001b[32m    218\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Perform a text search.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_search\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AgenticAI\\venv\\Lib\\site-packages\\ddgs\\ddgs.py:215\u001b[39m, in \u001b[36mDDGS._search\u001b[39m\u001b[34m(self, category, query, keywords, region, safesearch, timelimit, max_results, page, backend, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtimed out\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m:\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(err)\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m DDGSException(err \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNo results found.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mDDGSException\u001b[39m: RuntimeError: RuntimeError('error sending request for url (https://www.bing.com/search?q=When+google+antigravity+launched%3F&pq=When+google+antigravity+launched%3F&cc=wt&filters=ex1%3A%22ez5_20055_20420%22): client error (Connect)\\n\\nCaused by:\\n    0: client error (Connect)\\n    1: TLS handshake failed: cert verification failed - unable to get local issuer certificate [CERTIFICATE_VERIFY_FAILED]\\n    2: [CERTIFICATE_VERIFY_FAILED]\\n    3: [CERTIFICATE_VERIFY_FAILED]')"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Create the real search tool\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# Test it directly (No LLM involved yet)\n",
    "result = search_tool.invoke(\"When google antigravity launched?\")\n",
    "print(\"âœ… Internet Search SUCCESS\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Name: multiply\n",
      "Tool Description: Multiply two integers. Use this for math operations.\n",
      "Tool Args Schema: {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers. Use this for math operations.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def get_employee_email(name: str) -> str:\n",
    "    \"\"\"Get the email address of an employee by their full name.\"\"\"\n",
    "    # Mock Database\n",
    "    db = {\"Sharad Rajore\": \"sharad.r@zensar.com\", \"Alice Smith\": \"alice@zensar.com\"}\n",
    "    return db.get(name, \"Email not found\")\n",
    "\n",
    "print(f\"Tool Name: {multiply.name}\")\n",
    "print(f\"Tool Description: {multiply.description}\")\n",
    "print(f\"Tool Args Schema: {multiply.args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b081cd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sr43993\\AppData\\Local\\Temp\\ipykernel_18196\\4111713556.py:16: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  tavily_tool = TavilySearchResults(max_results=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Tavily Search...\n",
      "\n",
      "âœ… Search Results:\n",
      "SSLError(MaxRetryError(\"HTTPSConnectionPool(host='api.tavily.com', port=443): Max retries exceeded with url: /search (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\"))\n"
     ]
    }
   ],
   "source": [
    "# TAVILY SEARCH TOOL - Beginner Friendly Version\n",
    "# Step 1: Install the Tavily package\n",
    "#pip install tavily-python\n",
    "\n",
    "# Step 2: Import libraries\n",
    "import os\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Step 3: Get your API key\n",
    "# Go to https://tavily.com and sign up for a FREE API key\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    api_key = input(\"Paste your Tavily API Key here: \")\n",
    "    os.environ[\"TAVILY_API_KEY\"] = api_key\n",
    "\n",
    "# Step 4: Create the search tool\n",
    "tavily_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "# Step 5: Test it with a simple search\n",
    "print(\"Testing Tavily Search...\")\n",
    "result = tavily_tool.invoke(\"Who is the CEO of Zensar Technologies?\")\n",
    "print(\"\\nâœ… Search Results:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Custom Tools (The `@tool` Decorator)\n",
    "When we need custom logic, we use the `@tool` decorator. \n",
    "**CRITICAL:** The docstring is the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Name: multiply\n",
      "Tool Description: Multiply two integers. Use this for math operations.\n",
      "Tool Args Schema: {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers. Use this for math operations.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def get_employee_email(name: str) -> str:\n",
    "    \"\"\"Get the email address of an employee by their full name.\"\"\"\n",
    "    # Mock Database\n",
    "    db = {\"Sharad Rajore\": \"sharad.rajore@zensar.com\", \"Alice Smith\": \"alice@zensar.com\"}\n",
    "    return db.get(name, \"Email not found\")\n",
    "\n",
    "print(f\"Tool Name: {multiply.name}\")\n",
    "print(f\"Tool Description: {multiply.description}\")\n",
    "print(f\"Tool Args Schema: {multiply.args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Advanced Tools (StructuredTool & Pydantic)\n",
    "What if we need complex inputs? Like a tool that takes a JSON object?\n",
    "We use **Pydantic** to enforce data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TICKET CREATED: [Software] Priority 1 - Laptop crashed\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "# 1. Define the Schema (The \"Contract\")\n",
    "class TicketInput(BaseModel):\n",
    "    issue_type: str = Field(description=\"The type of issue: 'Hardware' or 'Software'\")\n",
    "    priority: int = Field(description=\"Priority level (1-5)\")\n",
    "    description: str = Field(description=\"Detailed description of the problem\")\n",
    "\n",
    "# 2. Define the Function\n",
    "def create_it_ticket(issue_type: str, priority: int, description: str) -> str:\n",
    "    return f\"TICKET CREATED: [{issue_type}] Priority {priority} - {description}\"\n",
    "\n",
    "# 3. Create the Tool\n",
    "ticket_tool = StructuredTool.from_function(\n",
    "    func=create_it_ticket,\n",
    "    name=\"create_ticket\",\n",
    "    description=\"Use this to log IT support tickets.\",\n",
    "    args_schema=TicketInput\n",
    ")\n",
    "\n",
    "# Test it manually to see Pydantic in action\n",
    "print(ticket_tool.invoke({\"issue_type\": \"Software\", \"priority\": \"1\", \"description\": \"Laptop crashed\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Binding (The Handshake)\n",
    "The LLM doesn't know these functions exist yet. We must **BIND** them.\n",
    "This converts Python functions -> OpenAI JSON Schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RAW LLM RESPONSE ---\n",
      "Content: \n",
      "Tool Calls: [{'name': 'create_ticket', 'args': {'issue_type': 'Hardware', 'priority': 1, 'description': 'The laptop screen is broken and needs immediate attention.'}, 'id': 'call_39xM3IKIBRk9N4FWRDUwtLGf', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "tools = [multiply, get_employee_email, ticket_tool]\n",
    "\n",
    "# Create a new LLM instance that KNOWS about the tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Let's inspect what happens when we call it\n",
    "query = \"My laptop screen is broken. It's urgent!\"\n",
    "response = llm_with_tools.invoke(query)\n",
    "\n",
    "#query = \"what is 2*2\"\n",
    "#response = llm_with_tools.invoke(query)\n",
    "\n",
    "print(\"--- RAW LLM RESPONSE ---\")\n",
    "print(f\"Content: {response.content}\")\n",
    "print(f\"Tool Calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: The Manual Execution Loop\n",
    "This is the most important part of Day 2. We will NOT use `AgentExecutor`. We will build the loop manually to understand **Message History**.\n",
    "\n",
    "**The Cycle:**\n",
    "1. **HumanMessage:** User input.\n",
    "2. **AIMessage:** LLM decides to call a tool.\n",
    "3. **ToolMessage:** We run the tool and pass the result back.\n",
    "4. **AIMessage:** LLM interprets the result and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 149, 'total_tokens': 182, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_672b6a21ba', 'id': 'chatcmpl-CgupSs7eAuYThVDwh4fsr2DsP5BX1', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--db1f14c3-a099-4d08-acdb-28cdd35dbe4c-0' tool_calls=[{'name': 'multiply', 'args': {'a': 55, 'b': 10}, 'id': 'call_tPrhKmr3nu10y5xAw0qSy5BC', 'type': 'tool_call'}] usage_metadata={'input_tokens': 149, 'output_tokens': 33, 'total_tokens': 182, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "AI Thought: [{'name': 'multiply', 'args': {'a': 55, 'b': 10}, 'id': 'call_tPrhKmr3nu10y5xAw0qSy5BC', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "# 1. User asks a question\n",
    "messages = [HumanMessage(content=\"Who is the pm of India? And multiply 55 * 10.\")]\n",
    "\n",
    "# 2. First LLM Call\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "print(ai_msg)\n",
    "messages.append(ai_msg) # IMPORTANT: Add AI's thought to history\n",
    "\n",
    "print(f\"AI Thought: {ai_msg.tool_calls}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4e312ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed multiply -> Result: 550\n"
     ]
    }
   ],
   "source": [
    "# 3. Execute Tools Manually\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\n",
    "        \"multiply\": multiply, \n",
    "        \"get_employee_email\": get_employee_email\n",
    "    }[tool_call[\"name\"]]\n",
    "    \n",
    "    # Run the tool\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    \n",
    "    # Create the ToolMessage\n",
    "    tool_msg = ToolMessage(tool_output, tool_call_id=tool_call[\"id\"])\n",
    "    messages.append(tool_msg)\n",
    "    print(f\"Executed {tool_call['name']} -> Result: {tool_output}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccc762e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Answer: The Prime Minister of India is Narendra Modi. The result of multiplying 55 by 10 is 550.\n"
     ]
    }
   ],
   "source": [
    "# 4. Second LLM Call (With full history)\n",
    "final_response = llm_with_tools.invoke(messages)\n",
    "print(f\"\\nFinal Answer: {final_response.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
