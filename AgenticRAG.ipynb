{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su2N3rWUT3fE",
        "outputId": "4c6426a7-7389-4a30-cd1a-cf4f2aef972f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.2.2)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (1.1.4)\n",
            "Requirement already satisfied: langchain-experimental in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (1.2.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (6.17.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.12.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (2.14.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (1.52.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (0.9.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (1.13.1)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (0.18.21)\n",
            "Requirement already satisfied: langchain-unstructured in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (1.0.0)\n",
            "Requirement already satisfied: langchain-pinecone in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (0.2.13)\n",
            "Requirement already satisfied: pinecone<8.0.0,>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (7.3.0)\n",
            "Requirement already satisfied: langchain-ollama in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (1.0.1)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 35)) (1.4.0)\n",
            "Requirement already satisfied: arxiv in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 36)) (2.3.1)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 37)) (1.0.4)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 44)) (1.3.7)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 45)) (0.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core->-r requirements.txt (line 2)) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core->-r requirements.txt (line 2)) (0.4.56)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core->-r requirements.txt (line 2)) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core->-r requirements.txt (line 2)) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core->-r requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core->-r requirements.txt (line 2)) (0.12.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 3)) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 3)) (2.32.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 3)) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 3)) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 3)) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 3)) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 3)) (2.3.5)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai->-r requirements.txt (line 4)) (2.9.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai->-r requirements.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (5.7.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 9)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 9)) (0.4.2)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 12)) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 12)) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 12)) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 12)) (8.3.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 12)) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 12)) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 12)) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 12)) (18.1.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 12)) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 12)) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 12)) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 12)) (0.9.1)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (3.4.4)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (6.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (4.13.5)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (2.15.0)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (2025.11.16)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (1.0.9)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (3.14.3)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (2.2.1)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (0.42.6)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (4.67.1)\n",
            "Requirement already satisfied: python-oxmsg in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (0.0.2)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.12/dist-packages (from unstructured->-r requirements.txt (line 17)) (1.1)\n",
            "Requirement already satisfied: onnxruntime<=1.19.2,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from langchain-unstructured->-r requirements.txt (line 18)) (1.19.2)\n",
            "Requirement already satisfied: httpx>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from langchain-pinecone->-r requirements.txt (line 20)) (0.28.1)\n",
            "Requirement already satisfied: simsimd>=5.9.11 in /usr/local/lib/python3.12/dist-packages (from langchain-pinecone->-r requirements.txt (line 20)) (6.5.3)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->-r requirements.txt (line 21)) (2025.11.12)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->-r requirements.txt (line 21)) (1.8.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->-r requirements.txt (line 21)) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->-r requirements.txt (line 21)) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->-r requirements.txt (line 21)) (2.3.0)\n",
            "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langchain-ollama->-r requirements.txt (line 27)) (0.6.1)\n",
            "Requirement already satisfied: feedparser~=6.0.10 in /usr/local/lib/python3.12/dist-packages (from arxiv->-r requirements.txt (line 36)) (6.0.12)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph->-r requirements.txt (line 37)) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph->-r requirements.txt (line 37)) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph->-r requirements.txt (line 37)) (0.2.15)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph->-r requirements.txt (line 37)) (3.6.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (1.4.3)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 44)) (0.38.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (5.4.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (1.39.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (34.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (3.11.5)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 44)) (4.25.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (1.22.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->-r requirements.txt (line 12)) (3.1.6)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->-r requirements.txt (line 12)) (2.13.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 44)) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 3)) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/dist-packages (from feedparser~=6.0.10->arxiv->-r requirements.txt (line 36)) (1.0.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 12)) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain-pinecone->-r requirements.txt (line 20)) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain-pinecone->-r requirements.txt (line 20)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain-pinecone->-r requirements.txt (line 20)) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.0->langchain-pinecone->-r requirements.txt (line 20)) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 44)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 44)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 44)) (0.30.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 8)) (5.9.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 44)) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 44)) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 44)) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 44)) (2.0.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 44)) (0.10)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph->-r requirements.txt (line 37)) (1.12.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 2)) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured->-r requirements.txt (line 18)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured->-r requirements.txt (line 18)) (25.9.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured->-r requirements.txt (line 18)) (1.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai->-r requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai->-r requirements.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 44)) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 44)) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 44)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 44)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb->-r requirements.txt (line 44)) (0.60b1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 12)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 12)) (2025.2)\n",
            "Requirement already satisfied: aiohttp-retry<3.0.0,>=2.9.1 in /usr/local/lib/python3.12/dist-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone->-r requirements.txt (line 20)) (2.9.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 44)) (4.0.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community->-r requirements.txt (line 3)) (3.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai->-r requirements.txt (line 4)) (2025.11.3)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb->-r requirements.txt (line 44)) (0.36.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 44)) (1.5.4)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured->-r requirements.txt (line 17)) (24.1.0)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured->-r requirements.txt (line 17)) (43.0.3)\n",
            "Requirement already satisfied: pypdf>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured->-r requirements.txt (line 17)) (6.4.2)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 44)) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 44)) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 44)) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 44)) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->unstructured->-r requirements.txt (line 17)) (2.8)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from html5lib->unstructured->-r requirements.txt (line 17)) (0.5.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured->-r requirements.txt (line 17)) (1.5.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.12/dist-packages (from python-oxmsg->unstructured->-r requirements.txt (line 17)) (0.47)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.1->unstructured-client->unstructured->-r requirements.txt (line 17)) (2.0.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 12)) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 44)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 44)) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r requirements.txt (line 44)) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r requirements.txt (line 44)) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r requirements.txt (line 44)) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 44)) (3.23.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.8.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->-r requirements.txt (line 12)) (3.0.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 8)) (4.5.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 44)) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.2.14)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured->-r requirements.txt (line 18)) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 44)) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured->-r requirements.txt (line 18)) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured->-r requirements.txt (line 17)) (2.23)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 44)) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygDTRibLT3B7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tlRxLYveTepB"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_core.tools import tool\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aqP86XExUCws"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import AzureChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "odUvMc3oUN80"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "\n",
        "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "azure_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
        "azure_deployment = os.getenv(\"AZURE_DEPLOYMENT_NAME\")\n",
        "azure_api_version = os.getenv(\"AZURE_API_VERSION\")\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    api_key=azure_api_key,\n",
        "    azure_deployment=azure_deployment,\n",
        "    api_version=azure_api_version,\n",
        "    max_tokens=2000,\n",
        "    temperature=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VQwtKNBnUpzn"
      },
      "outputs": [],
      "source": [
        "@tool(\"GoogleSearch\")\n",
        "def search(query_string: str):\n",
        "    \"\"\"\n",
        "    Useful to search for any kinds of information and\n",
        "    when you need to search the internet for any kinds of information, use this tool.\n",
        "    Prefer this tool when you search for long queries.\n",
        "    Should not be used for Article search or Topic Search.\n",
        "    \"\"\"\n",
        "\n",
        "    search = GoogleSerperAPIWrapper()\n",
        "\n",
        "    return search.run(query_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h7E6pR27UsAJ"
      },
      "outputs": [],
      "source": [
        "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=1000)\n",
        "wiki = WikipediaQueryRun(\n",
        "    name=\"WikiepdiaSearch\",\n",
        "    description=\"Use this tool when you want to analyze for information on Wikipedia by Terms, Keywords or any Topics.\",\n",
        "    api_wrapper=api_wrapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaZDbAI0VAIa",
        "outputId": "98b30000-8346-427d-ea3c-89bff57ee65d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EAkeOGkqVI_h"
      },
      "outputs": [],
      "source": [
        "azure_embedding_deployment = os.getenv(\n",
        "    \"AZURE_EMBEDDING_DEPLOYMENT_NAME\", \"text-embedding-3-large\")\n",
        "\n",
        "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
        "docs = loader.load()\n",
        "documents = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 200\n",
        ").split_documents(docs)\n",
        "\n",
        "embeddings = AzureOpenAIEmbeddings(azure_endpoint=azure_endpoint,\n",
        "                                    model=\"text-embedding-3-large\",\n",
        "                                    api_key=azure_api_key,\n",
        "                                    deployment=azure_embedding_deployment,\n",
        "                                    dimensions=3072,\n",
        "                                    )\n",
        "vectordatabase = FAISS.from_documents(documents, embeddings)\n",
        "retriever = vectordatabase.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HSDY96et9c4Z"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y langchain langchain-core langchain-community\n",
        "!pip install -U langchain langchain-core langchain-community\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jqHzAquFWctM",
        "outputId": "72505a8d-f162-4f18-e451-d71071c24b88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'langsmith_search'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from langchain_core.tools import create_retriever_tool\n",
        "\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"langsmith_search\",\n",
        "    \"search for information about langsmith. for any questions related to langsmith, you must use this tool\"\n",
        ")\n",
        "\n",
        "retriever_tool.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "grMW5U6ibP_h"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities import ArxivAPIWrapper\n",
        "from langchain_community.tools import ArxivQueryRun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ujgzFDEobYhk"
      },
      "outputs": [],
      "source": [
        "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=1000)\n",
        "arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Faxlhu6Vbcxw",
        "outputId": "3f32d5f4-5ae9-4c45-e2ba-11a6eda12d46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=1000)),\n",
              " StructuredTool(name='GoogleSearch', description='Useful to search for any kinds of information and\\nwhen you need to search the internet for any kinds of information, use this tool.\\nPrefer this tool when you search for long queries.\\nShould not be used for Article search or Topic Search.', args_schema=<class 'langchain_core.utils.pydantic.GoogleSearch'>, func=<function search at 0x7a3146e7fe20>),\n",
              " WikipediaQueryRun(name='WikiepdiaSearch', description='Use this tool when you want to analyze for information on Wikipedia by Terms, Keywords or any Topics.', api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.12/dist-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=1000)),\n",
              " StructuredTool(name='langsmith_search', description='search for information about langsmith. for any questions related to langsmith, you must use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=<function create_retriever_tool.<locals>.func at 0x7a3098bfaca0>, coroutine=<function create_retriever_tool.<locals>.afunc at 0x7a3098bfade0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tools = [arxiv, search, wiki, retriever_tool]\n",
        "tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tblvdVW-D2PV",
        "outputId": "d392cfcf-d605-4523-a792-b405f7b74e02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful AI assistant.'), additional_kwargs={}),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful AI assistant.\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "prompt.messages\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wveVo8ubfhM",
        "outputId": "8024c124-e0ba-4fe3-eac0-5e0ebc89f757"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful AI assistant.'), additional_kwargs={}),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful AI assistant.\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "prompt.messages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "P7Ib4NH5bjne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab34eb4-967d-4b8e-9b13-8581b5bff162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3333576309.py:4: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
            "  agent_executor = create_react_agent(\n"
          ]
        }
      ],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "agent_executor = create_react_agent(\n",
        "    llm,\n",
        "    tools = tools\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "y1uXrER2boY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d56560e7-8955-4072-9a41-f710bc357457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 255, 'total_tokens': 272, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4a331a0222', 'id': 'chatcmpl-Cnoc1NsxLPc6AXCPrrDBp9avmhhDp', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='lc_run--019b2d20-79a2-7ef0-9515-36c8d875169a-0', tool_calls=[{'name': 'langsmith_search', 'args': {'query': 'LangSmith'}, 'id': 'call_mo31D2NsLyYxBOqq5YjuNPaS', 'type': 'tool_call'}], usage_metadata={'input_tokens': 255, 'output_tokens': 17, 'total_tokens': 272, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "***********\n",
            "{'tools': {'messages': [ToolMessage(content='LangSmith is framework agnostic, so you can use it with or without LangChains open-source libraries\\nlangchain and langgraph.\\nPrototype locally, then move to production with integrated monitoring and evaluation to build more reliable AI systems.\\nLangGraph Platform is now LangSmith Deployment. For more information, check out the Changelog.\\n\\u200bGet started\\nCreate an accountSign up at smith.langchain.com (no credit card required).\\nYou can log in with Google, GitHub, or email.Create an API keyGo to your Settings page  API Keys  Create API Key.\\nCopy the key and save it securely.\\nOnce your account and API key are ready, choose a quickstart to begin building with LangSmith:\\n\\nLangSmith docs - Docs by LangChainSkip to main contentDocs by LangChain home pageLangSmithSearch...KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationLangSmith docsGet startedObservabilityEvaluationPrompt engineeringDeploymentAgent BuilderPlatform setupReferenceOverviewPlansCreate an account and API keyAccount administrationOverviewSet up a workspaceManage organizations using the APIManage billingSet up resource tagsUser managementAdditional resourcesPolly (Beta)Data managementAccess control & AuthenticationScalability & resilienceFAQsRegions FAQPricing FAQLangSmith statusLangSmith docsCopy pageCopy pageLangSmith provides tools for developing, debugging, and deploying LLM applications.\\nIt helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\\nLangSmith is framework agnostic, so you can use it with or without LangChains open-source libraries\\nlangchain and langgraph.\\n\\n\\u200bMore ways to build\\nPlatform setupUse LangSmith in managed cloud, in a self-hosted environment, or hybrid to match your infrastructure and compliance needs.Choose how to set up LangSmithAgent Builder (Beta)Design and deploy AI agents visually with a no-code interfaceperfect for rapid prototyping and getting started without writing code.Build an agentStudioUse a visual interface to design, test, and refine applications end-to-end.Develop with StudioPrompt testingIterate on prompts with built-in versioning and collaboration to ship improvements faster.Test your prompts\\nLangSmith meets the highest standards of data security and privacy with HIPAA, SOC 2 Type 2, and GDPR compliance. For more information, see the Trust Center.\\n\\u200bWorkflow\\nLangSmith combines observability, evaluation, deployment, and platform setup in one integrated workflowfrom local development to production.\\n\\nCopy the key and save it securely.\\nOnce your account and API key are ready, choose a quickstart to begin building with LangSmith:\\nObservabilityGain visibility into every step your application takes to debug faster and improve reliability.Start tracingEvaluationMeasure and track quality over time to ensure your AI applications are consistent and trustworthy.Evaluate your appDeploymentDeploy your agents as Agent Servers, ready to scale in production.Deploy your agents\\n\\u200bMore ways to build', name='langsmith_search', id='49747825-1435-4d34-92a9-86c14811c6d4', tool_call_id='call_mo31D2NsLyYxBOqq5YjuNPaS')]}}\n",
            "***********\n",
            "{'agent': {'messages': [AIMessage(content='LangSmith is a versatile platform designed for developing, debugging, and deploying large language model (LLM) applications. It is framework agnostic, meaning it can be used with or without LangChains open-source libraries, such as langchain and langgraph. LangSmith provides an integrated workflow that includes observability, evaluation, deployment, and platform setup, facilitating the transition from local development to production.\\n\\n### Key Features of LangSmith:\\n\\n1. **Observability**: Gain visibility into every step your application takes, which helps in faster debugging and improving reliability.\\n\\n2. **Evaluation**: Measure and track the quality of your AI applications over time to ensure consistency and trustworthiness.\\n\\n3. **Deployment**: Deploy your AI agents as Agent Servers, ready to scale in production environments.\\n\\n4. **Platform Setup**: LangSmith can be used in managed cloud, self-hosted environments, or hybrid setups to match infrastructure and compliance needs.\\n\\n5. **Agent Builder (Beta)**: Design and deploy AI agents visually with a no-code interface, ideal for rapid prototyping.\\n\\n6. **Prompt Testing**: Iterate on prompts with built-in versioning and collaboration tools to ship improvements faster.\\n\\n7. **Security and Compliance**: LangSmith meets high standards of data security and privacy, including HIPAA, SOC 2 Type 2, and GDPR compliance.\\n\\n### Getting Started with LangSmith:\\n\\n- **Create an Account**: Sign up at smith.langchain.com without needing a credit card. You can log in using Google, GitHub, or email.\\n- **API Key**: Generate an API key from your settings page to start building with LangSmith.\\n\\nLangSmith is designed to help developers trace requests, evaluate outputs, test prompts, and manage deployments efficiently, all in one place.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 361, 'prompt_tokens': 863, 'total_tokens': 1224, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4a331a0222', 'id': 'chatcmpl-Cnoc2qrMClI3pL7RSYw6AOW0b8ZFO', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='lc_run--019b2d20-7c8e-7262-8615-0549e69c9e26-0', usage_metadata={'input_tokens': 863, 'output_tokens': 361, 'total_tokens': 1224, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "***********\n"
          ]
        }
      ],
      "source": [
        "for stream in agent_executor.stream({\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"tell me about langsmith\")\n",
        "    ]\n",
        "}):\n",
        "    print(stream)\n",
        "    print(\"***********\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lLHkdA-LclRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "316517fb-ebca-4f86-8987-bc5f7af31822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 264, 'total_tokens': 283, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4a331a0222', 'id': 'chatcmpl-CnocTpKAIuToEEk2sPOqJE6V7Gji2', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='lc_run--019b2d20-e53a-72b1-8e56-992be5785b2b-0', tool_calls=[{'name': 'arxiv', 'args': {'query': '2412.16446'}, 'id': 'call_ZFRCP346NbEct1w1HFeTZf7K', 'type': 'tool_call'}], usage_metadata={'input_tokens': 264, 'output_tokens': 19, 'total_tokens': 283, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "***********\n",
            "{'tools': {'messages': [ToolMessage(content='Published: 2024-12-21\\nTitle: Sensitive Image Classification by Vision Transformers\\nAuthors: Hanxian He, Campbell Wilson, Thanh Thi Nguyen, Janis Dalins\\nSummary: When it comes to classifying child sexual abuse images, managing similar inter-class correlations and diverse intra-class correlations poses a significant challenge. Vision transformer models, unlike conventional deep convolutional network models, leverage a self-attention mechanism to capture global interactions among contextual local elements. This allows them to navigate through image patches effectively, avoiding incorrect correlations and reducing ambiguity in attention maps, thus proving their efficacy in computer vision tasks. Rather than directly analyzing child sexual abuse data, we constructed two datasets: one comprising clean and pornographic images and another with three classes, which additionally include images indicative of pornography, sourced from Reddit and Google Open Images data. In our experiments, we also', name='arxiv', id='f383e528-b4a6-4b4a-ad98-c5b4ce3577e4', tool_call_id='call_ZFRCP346NbEct1w1HFeTZf7K')]}}\n",
            "***********\n",
            "{'agent': {'messages': [AIMessage(content='The paper titled \"Sensitive Image Classification by Vision Transformers\" discusses the challenges of classifying images related to child sexual abuse, particularly due to the similar inter-class correlations and diverse intra-class correlations. The authors explore the use of Vision Transformer models, which utilize a self-attention mechanism to capture global interactions among contextual local elements. This approach helps in effectively navigating image patches, avoiding incorrect correlations, and reducing ambiguity in attention maps, thereby enhancing performance in computer vision tasks.\\n\\nInstead of directly analyzing child sexual abuse data, the authors constructed two datasets: one with clean and pornographic images, and another with three classes that include images indicative of pornography. These datasets were sourced from Reddit and Google Open Images data. The paper likely details experiments conducted using these datasets to demonstrate the efficacy of Vision Transformers in sensitive image classification tasks.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 163, 'prompt_tokens': 462, 'total_tokens': 625, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4a331a0222', 'id': 'chatcmpl-CnocUdz4CS5BnQdwGLwEbWX8gPkkk', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='lc_run--019b2d20-e981-76d3-859a-902e3b736ca0-0', usage_metadata={'input_tokens': 462, 'output_tokens': 163, 'total_tokens': 625, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "***********\n"
          ]
        }
      ],
      "source": [
        "for stream in agent_executor.stream({\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"whats the paper 2412.16446 talk about it?\")\n",
        "    ]\n",
        "}):\n",
        "    print(stream)\n",
        "    print(\"***********\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TrdBcQQJcs_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ed4ccf-a73b-45c9-b517-925dd3fe87ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 252, 'total_tokens': 272, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4a331a0222', 'id': 'chatcmpl-Cnocs0JVE1ArpT3DBkMVCQ61Ihywi', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='lc_run--019b2d21-4656-75f1-abe8-1cf1113f9959-0', tool_calls=[{'name': 'WikiepdiaSearch', 'args': {'query': 'Indian Constitution'}, 'id': 'call_UjRri1Po88kcrs3N4ARgkt2Y', 'type': 'tool_call'}], usage_metadata={'input_tokens': 252, 'output_tokens': 20, 'total_tokens': 272, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "***********\n",
            "{'tools': {'messages': [ToolMessage(content=\"Page: Constitution of India\\nSummary: The Constitution of India is the supreme legal document of India, and the longest written national constitution in the world. The document lays down the framework that demarcates fundamental political code, structure, procedures, powers, and duties of government institutions and sets out fundamental rights, directive principles, and the duties of citizens.\\nIt espouses constitutional supremacy (not parliamentary supremacy found in the United Kingdom, since it was created by a constituent assembly rather than Parliament) and was adopted with a declaration in its preamble. The Indian Constitution does not contain a provision to limit the powers of the parliament to amend the constitution. However, the Supreme Court in Kesavananda Bharati v. State of Kerala held that there were certain features of the Constitution so integral to its functioning and existence that they could never be cut out of the constitution (known as the 'Basic Structure' Doctrine).\\n\", name='WikiepdiaSearch', id='3cd54e93-0a0b-4098-a6ac-89eed2bf123c', tool_call_id='call_UjRri1Po88kcrs3N4ARgkt2Y')]}}\n",
            "***********\n",
            "{'agent': {'messages': [AIMessage(content=\"The Constitution of India is the supreme legal document of India and is recognized as the longest written national constitution in the world. It establishes the fundamental political code, structure, procedures, powers, and duties of government institutions and outlines the fundamental rights, directive principles, and duties of citizens.\\n\\nKey features include:\\n\\n- **Constitutional Supremacy**: Unlike the United Kingdom's parliamentary supremacy, the Indian Constitution was created by a constituent assembly, emphasizing constitutional supremacy.\\n- **Amendment Powers**: The Constitution does not inherently limit the powers of the parliament to amend it. However, the Supreme Court, in the case of Kesavananda Bharati v. State of Kerala, established the 'Basic Structure' Doctrine, which asserts that certain features of the Constitution are so essential that they cannot be altered or removed.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 165, 'prompt_tokens': 463, 'total_tokens': 628, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4a331a0222', 'id': 'chatcmpl-CnocuROH4a1sr5BXQi2RHvGMQ7kMy', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='lc_run--019b2d21-4d91-77c3-8974-894ea3bb4663-0', usage_metadata={'input_tokens': 463, 'output_tokens': 165, 'total_tokens': 628, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "***********\n"
          ]
        }
      ],
      "source": [
        "for stream in agent_executor.stream({\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Indian Constitution\")\n",
        "    ]\n",
        "}):\n",
        "    print(stream)\n",
        "    print(\"***********\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}