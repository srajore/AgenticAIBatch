{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Module 1: The \"Why\" of Reducers\n",
    "**Objective:** Understand why standard Python lists overwrite data in LangGraph and how Reducers fix this.\n",
    "\n",
    "### Prerequisites\n",
    "Ensure you have the necessary libraries installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in d:\\agenticai\\venv\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: langchain-openai in d:\\agenticai\\venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-core in d:\\agenticai\\venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in d:\\agenticai\\venv\\lib\\site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in d:\\agenticai\\venv\\lib\\site-packages (from langgraph) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in d:\\agenticai\\venv\\lib\\site-packages (from langgraph) (0.2.10)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in d:\\agenticai\\venv\\lib\\site-packages (from langgraph) (2.12.4)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in d:\\agenticai\\venv\\lib\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in d:\\agenticai\\venv\\lib\\site-packages (from langchain-openai) (2.8.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in d:\\agenticai\\venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\agenticai\\venv\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\agenticai\\venv\\lib\\site-packages (from langchain-core) (0.4.48)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\agenticai\\venv\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\agenticai\\venv\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\agenticai\\venv\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\agenticai\\venv\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\agenticai\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in d:\\agenticai\\venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in d:\\agenticai\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in d:\\agenticai\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\agenticai\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\agenticai\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\agenticai\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\agenticai\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\agenticai\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\agenticai\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in d:\\agenticai\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\agenticai\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\agenticai\\venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\agenticai\\venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\agenticai\\venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\agenticai\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\agenticai\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
      "Requirement already satisfied: certifi in d:\\agenticai\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\agenticai\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\agenticai\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\agenticai\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\agenticai\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: colorama in d:\\agenticai\\venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph langchain-openai langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flavor 1: The Broken State (Default Behavior)\n",
    "In a standard `TypedDict`, updating a key replaces the old value. Watch how the user's input is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUN 1 ---\n",
      "Result: ['Bot: I am a goldfish. I forget everything.']\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 1. Define State (No Reducer)\n",
    "class BrokenState(TypedDict):\n",
    "    messages: list[str] \n",
    "\n",
    "# 2. Define Node\n",
    "def chatbot_node(state: BrokenState):\n",
    "    # This return statement REPLACES the 'messages' key\n",
    "    return {\"messages\": [\"Bot: I am a goldfish. I forget everything.\"]}\n",
    "\n",
    "# 3. Build Graph\n",
    "builder = StateGraph(BrokenState)\n",
    "builder.add_node(\"chatbot\", chatbot_node)\n",
    "\n",
    "\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "\n",
    "broken_graph = builder.compile()\n",
    "\n",
    "# 4. Execute\n",
    "print(\"--- RUN 1 ---\")\n",
    "res = broken_graph.invoke({\"messages\": [\"User: Hi\"]})\n",
    "print(f\"Result: {res['messages']}\") \n",
    "# FAIL: The user's 'Hi' is gone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flavor 2: The Manual Fix\n",
    "We can fix this by manually fetching the old list and appending to it. This works, but it is error-prone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUN 1 ---\n",
      "Result: ['User: Hi', 'Bot: I remember, but I had to do the work manually!']\n"
     ]
    }
   ],
   "source": [
    "# 1. State\n",
    "class ManualState(TypedDict):\n",
    "    messages: list \n",
    "\n",
    "# 2. Node (Manual Appending Logic)\n",
    "def chatbot_node(state: ManualState):\n",
    "    # A. FETCH existing\n",
    "    existing = state['messages']\n",
    "    # B. CREATE new\n",
    "    new_msg = \"Bot: I remember, but I had to do the work manually!\"\n",
    "    # C. COMBINE manually\n",
    "    return {\"messages\": existing + [new_msg]}\n",
    "\n",
    "# 3. Build Graph\n",
    "builder = StateGraph(ManualState)\n",
    "builder.add_node(\"chatbot\", chatbot_node)\n",
    "\n",
    "\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "\n",
    "manual_graph = builder.compile()\n",
    "\n",
    "# 4. Execute\n",
    "print(\"--- RUN 1 ---\")\n",
    "res = manual_graph.invoke({\"messages\": [\"User: Hi\"]})\n",
    "print(f\"Result: {res['messages']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flavor 3: The LangGraph Way (Reducers)\n",
    "We use `Annotated` and `add_messages`. This tells LangGraph to handle the appending automatically. This is the best practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUN 1 ---\n",
      "Result: [HumanMessage(content='User: Hi', additional_kwargs={}, response_metadata={}, id='eff15446-689c-4670-a84d-3321b2064b16'), AIMessage(content='Bot: I remember everything automatically!', additional_kwargs={}, response_metadata={}, id='9695955d-54f0-4a0b-a1fe-938c3bcb8c92')]\n",
      "\n",
      "--- RUN 2 ---\n",
      "Final History: [HumanMessage(content='User: Hi', additional_kwargs={}, response_metadata={}, id='eff15446-689c-4670-a84d-3321b2064b16'), AIMessage(content='Bot: I remember everything automatically!', additional_kwargs={}, response_metadata={}, id='9695955d-54f0-4a0b-a1fe-938c3bcb8c92'), HumanMessage(content='User: Bye', additional_kwargs={}, response_metadata={}, id='08e51114-52fc-4aa1-aedd-bccb235ef10b'), AIMessage(content='Bot: I remember everything automatically!', additional_kwargs={}, response_metadata={}, id='bce5dd4b-37f2-40af-af2f-3cf19638894d')]\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages \n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 1. State (Annotated with Reducer)\n",
    "class SmartState(TypedDict):\n",
    "    # \"When you get a new message, ADD it to the list. Don't replace.\"\n",
    "    messages: Annotated[list, add_messages] \n",
    "\n",
    "# 2. Node (Pure Logic)\n",
    "def chatbot_node(state: SmartState):\n",
    "    # We just return the NEW item. LangGraph handles the rest.\n",
    "    return {\"messages\": [AIMessage(content=\"Bot: I remember everything automatically!\")]}\n",
    "\n",
    "# 3. Graph\n",
    "builder = StateGraph(SmartState)\n",
    "\n",
    "builder.add_node(\"chatbot\", chatbot_node)\n",
    "\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "smart_graph = builder.compile()\n",
    "\n",
    "# 4. Execute\n",
    "print(\"--- RUN 1 ---\")\n",
    "res = smart_graph.invoke({\"messages\": [HumanMessage(content=\"User: Hi\")]})\n",
    "print(f\"Result: {res['messages']}\")\n",
    "\n",
    "print(\"\\n--- RUN 2 ---\")\n",
    "# Simulate continuing conversation\n",
    "current_history = res['messages']\n",
    "res_2 = smart_graph.invoke({\"messages\": current_history + [HumanMessage(content=\"User: Bye\")]})\n",
    "print(f\"Final History: {res_2['messages']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
